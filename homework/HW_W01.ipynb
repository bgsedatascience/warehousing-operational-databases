{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import psycopg2\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #--\n",
    "#\n",
    "# DBConnection Class\n",
    "#\n",
    "#-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #-- #--\n",
    "class DBConnection():\n",
    "    \"\"\"Class to handle the database connection\"\"\"\n",
    "    def __init__(self,\n",
    "                 dbname=\"company_db\",\n",
    "                 user=\"postgres\",\n",
    "                 host=\"localhost\"):\n",
    "        \"\"\"Constructor initialises connection and cursor\"\"\"\n",
    "        self.configure_conn(dbname, user, host)\n",
    "        self.connect()\n",
    "        self.open_cursor()\n",
    "\n",
    "    def __del__(self):\n",
    "        \"\"\"Destructor to tidy up if required\"\"\"\n",
    "        if self.cur is not None:\n",
    "            self.close_cursor()\n",
    "        if self.conn is not None:\n",
    "            self.disconnect()\n",
    "\n",
    "    def connect(self):\n",
    "        \"\"\"Connect to configured host\"\"\"\n",
    "        conn_str = f\"dbname={self.dbname} user={self.user} host={self.host}\"\n",
    "        self.conn = psycopg2.connect(conn_str)\n",
    "\n",
    "    def configure_conn(self, dbname, user, host):\n",
    "        \"\"\"Configure connection\"\"\"\n",
    "        self.dbname=dbname\n",
    "        self.user=user\n",
    "        self.host=host\n",
    "\n",
    "    def disconnect(self, close_cursor_b=False):\n",
    "        \"\"\"Close connection to database\"\"\"\n",
    "        if close_cursor_b:\n",
    "            self.close_cursor\n",
    "        self.conn.close()\n",
    "        self.conn = None\n",
    "\n",
    "    def is_connected(self):\n",
    "        \"\"\"Check if connection is active\"\"\"\n",
    "        if self.conn is None:\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "\n",
    "    def open_cursor(self):\n",
    "        \"\"\"Open database cursor\"\"\"\n",
    "        self.cur = self.conn.cursor()\n",
    "\n",
    "    def close_cursor(self):\n",
    "        \"\"\"Close database cursor\"\"\"\n",
    "        self.cur.close()\n",
    "        self.cur = None\n",
    "\n",
    "    def select_query(self, query):\n",
    "        \"\"\"Execute SELECT query\"\"\"\n",
    "        self.cur.execute(query)\n",
    "        return self.cur.fetchall()\n",
    "\n",
    "    def insert_query(self, query, var_tuple):\n",
    "        \"\"\"Execute INSERT query\"\"\"\n",
    "        self.cur.execute(query, var_tuple)\n",
    "        self.conn.commit()\n",
    "\n",
    "    def _delete_query(self, query):\n",
    "        \"\"\"Execute DELETE query :: Testing only\"\"\"\n",
    "        # Not a fan of providing direct delete methods, testing only...\n",
    "        self.cur.execute(query)\n",
    "        self.conn.commit()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_query(row, table, query_type):\n",
    "    \"\"\"Construct query from row for table\"\"\"\n",
    "    # Abstracted to allow for additon of UPDATE and SELECT later on\n",
    "    # if required\n",
    "    if query_type == \"INSERT\":\n",
    "        return build_insert_query(row, table)\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "def build_insert_query(row, table):\n",
    "    \"\"\"Construct insert query from row for table\"\"\"\n",
    "    query_columns = \"\"\n",
    "    variable_list = list()\n",
    "    for key in row.keys():\n",
    "        # Insert is columns then values, so construct as two strings\n",
    "        query_columns += f\"{key}, \"\n",
    "        # Use format value to handle value types in SQL\n",
    "        variable_list.append(row[key])\n",
    "    values = \"%s, \" * len(row.keys())\n",
    "    # Index to -2 to remove \", \" from last value\n",
    "    query = f\"INSERT INTO {table} ({query_columns[:-2]}) VALUES ({values[:-2]})\"\n",
    "    return query, variable_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_table(conn, table_name, frame):\n",
    "    \"\"\"Load a dataframe into a specified table\"\"\"\n",
    "    # Build table\n",
    "    for index, row in frame.iterrows():\n",
    "        query_str, var_tuple = build_query(row, table_name, \"INSERT\")\n",
    "        #print(query_str)\n",
    "        conn.insert_query(query_str, var_tuple)\n",
    "\n",
    "def _torch_tables(conn, tables=['products', 'orders',\n",
    "                                'customers', 'employees', 'offices',  ]):\n",
    "    \"\"\"Delete the contents of the database\"\"\"\n",
    "    # This is for testing only, method should not be used.\n",
    "    for table in tables:\n",
    "        conn._delete_query(f\"DELETE FROM {table};\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_products_file(conn, filename):\n",
    "    \"\"\"Load the records from the products file\"\"\"\n",
    "    products = pd.read_csv(filename)\n",
    "    # From products, take all columns\n",
    "    load_table(conn, 'products', products)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders_file(conn, filename):\n",
    "    \"\"\"Load the records from the orders file\"\"\"\n",
    "    orders_full = pd.read_csv(filename)\n",
    "    # Convert byte columns to string literals\n",
    "    orders_full[\"customer_location\"] = (orders_full[\"customer_location\"]\n",
    "        .apply(ast.literal_eval))\n",
    "    # Fix nulls to None as it messes with the dates\n",
    "    orders_full = orders_full.where(pd.notnull(orders_full), None)\n",
    "    # Split orders into three tables; customers, orders and order_items\n",
    "    load_customers_table(conn, orders_full)\n",
    "    #Second part, orders\n",
    "    load_orders_table(conn, orders_full)\n",
    "    # Third part, order_items\n",
    "    load_order_items_table(conn, orders_full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_customers_table(conn, orders_full):\n",
    "    \"\"\"Load the records into the customers_table\"\"\"\n",
    "    customers_col_list = ['customer_number', 'customer_name',\n",
    "                          'contact_last_name', 'contact_first_name',\n",
    "                          'city', 'state', 'country',\n",
    "                          'sales_rep_employee_number', 'credit_limit',\n",
    "                          'customer_location']\n",
    "    customers_df = orders_full[customers_col_list].drop_duplicates()\n",
    "    load_table(conn, 'customers', customers_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_orders_table(conn, orders_full):\n",
    "    \"\"\"Load the records into the orders table\"\"\"\n",
    "    orders_col_list = [ 'order_number', 'customer_number', 'order_date',\n",
    "                       'required_date', 'shipped_date', 'status',\n",
    "                       'comments' ]\n",
    "    orders_df = orders_full[orders_col_list].drop_duplicates()\n",
    "    load_table(conn, 'orders', orders_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_order_items_table(conn, orders_full):\n",
    "    \"\"\"Load the records into the order_items table\"\"\"\n",
    "    # Create new index for order_item that combines the order_number with the\n",
    "    # line number\n",
    "    orders_full[\"order_item_number\"] = (orders_full[\"order_number\"]\n",
    "        .astype(str) + \"-\" +\n",
    "        orders_full[\"order_line_number\"].astype(str))\n",
    "    order_items_col_list = [ 'order_item_number', 'order_number',\n",
    "                            'product_code', 'quantity_ordered',\n",
    "                            'price_each', 'order_line_number']\n",
    "    order_items_df = orders_full[order_items_col_list]\n",
    "    load_table(conn, 'order_items', order_items_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_employees_file(conn, filename):\n",
    "    \"\"\"Load the records from the employees_file\"\"\"\n",
    "    employees_full = pd.read_csv(filename)\n",
    "    employees_full[\"office_location\"] = (employees_full[\"office_location\"]\n",
    "        .apply(ast.literal_eval))\n",
    "    # Split the employees table into two tables; offices and employees\n",
    "    load_office_table(conn, employees_full)\n",
    "    # Second part, employees\n",
    "    load_employees_table(conn, employees_full)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_office_table(conn, employees_full):\n",
    "    \"\"\"Load the records into the offices table\"\"\"\n",
    "    offices_col_list = {'office_code', 'city', 'state', 'country',\n",
    "                        'office_location' }\n",
    "    offices_df = employees_full[offices_col_list].drop_duplicates()\n",
    "    load_table(conn, 'offices', offices_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_employees_table(conn, employees_full):\n",
    "    \"\"\"Load the records into the employees table\"\"\"\n",
    "    employees_col_list = {'employee_number', 'last_name', 'first_name',\n",
    "                          'reports_to', 'job_title', 'office_code'}\n",
    "    employees_df = employees_full[employees_col_list]\n",
    "    load_table(conn, 'employees', employees_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert complete.\n"
     ]
    }
   ],
   "source": [
    "# Create database db_connection\n",
    "conn = DBConnection()\n",
    "load_products_file(conn, \"extracts/products.csv\")\n",
    "load_employees_file(conn, 'extracts/employees.csv')\n",
    "load_orders_file(conn, 'extracts/orders.csv')\n",
    "if conn.is_connected():\n",
    "    conn.disconnect(True)\n",
    "print(\"Insert complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
